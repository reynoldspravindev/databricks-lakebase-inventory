{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72ca9ac1-0add-4a02-8ffd-364e32358bc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks Lakebase Inventory App - Automated Deployment\n",
    "\n",
    "This notebook automates the deployment of the Lakebase Inventory Management System.\n",
    "\n",
    "## What This Notebook Does:\n",
    "1. Creates a Lakebase (Managed Postgres) database instance\n",
    "2. Creates a Databricks App\n",
    "3. Creates a Secret Scope with Flask secret key\n",
    "4. Adds the Lakebase database as an app resource\n",
    "5. Clones the GitHub repository to the workspace\n",
    "6. Creates an app.yaml configuration file\n",
    "7. Deploys the Databricks App\n",
    "8. Provides redeployment commands\n",
    "\n",
    "## Prerequisites:\n",
    "- Update the variables in 0Setup notebook.\n",
    "- Unity Catalog enabled workspace\n",
    "- Appropriate permissions to create databases, apps, and secret scopes\n",
    "- Databricks SDK installed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17e6d59b-f4d4-46f9-8559-c86c3442e130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../0 - SETUP/0 - Setup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc0a668a-c670-4fa2-8cbf-cf005848e185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import secrets\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from datetime import timedelta, datetime\n",
    "from time import sleep\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "411396f9-951e-4e5d-bb1b-d65c963bd7f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1: Create Lakebase (Managed Postgres) Database Instance\n",
    "\n",
    "This creates a managed PostgreSQL database instance in Unity Catalog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc1df7c3-ac14-4454-9e5b-faa7197e4b90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Step 1: Creating Lakebase Database Instance...\\n\")\n",
    "\n",
    "try:\n",
    "    # Create the Lakebase database instance\n",
    "    # Using the correct SDK method: create_database_instance_and_wait\n",
    "    from databricks.sdk.service.database import DatabaseInstance\n",
    "    \n",
    "    database_instance = DatabaseInstance(\n",
    "        name=LAKEBASE_DB_NAME,\n",
    "        capacity=LAKEBASE_CAPACITY  # Valid values: \"CU_1\", \"CU_2\", \"CU_4\", \"CU_8\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Creating database '{LAKEBASE_DB_NAME}' with capacity: {LAKEBASE_CAPACITY}\")\n",
    "    \n",
    "    # Create and wait for the database instance to be ready\n",
    "    lakebase_db = w.database.create_database_instance_and_wait(\n",
    "        database_instance=database_instance,\n",
    "        timeout=timedelta(minutes=20)\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Lakebase database '{LAKEBASE_DB_NAME}' created successfully!\")\n",
    "    print(f\"  Database Name: {lakebase_db.name}\")\n",
    "    print(f\"  Status: {lakebase_db.state}\")\n",
    "    \n",
    "    # Store database details\n",
    "    LAKEBASE_DB_ID = lakebase_db.name\n",
    "    \n",
    "except Exception as e:\n",
    "    # Check if database already exists\n",
    "    if \"already exists\" in str(e).lower() or \"AlreadyExists\" in str(e):\n",
    "        print(f\" Database '{LAKEBASE_DB_NAME}' already exists. Using existing database.\")\n",
    "        # List databases and find ours\n",
    "        databases = list(w.database.list_database_instances())\n",
    "        lakebase_db = next((db for db in databases if db.name == LAKEBASE_DB_NAME), None)\n",
    "        if lakebase_db:\n",
    "            LAKEBASE_DB_ID = lakebase_db.name\n",
    "            print(f\"  Database Name: {LAKEBASE_DB_ID}\")\n",
    "            print(f\"  Status: {lakebase_db.state}\")\n",
    "        else:\n",
    "            raise Exception(f\"Could not find database '{LAKEBASE_DB_NAME}'\")\n",
    "    else:\n",
    "        print(f\"âœ— Error creating Lakebase database: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ec261c2-1e68-403f-ab84-231068b3c5d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2: Generate Flask Secret Key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baf0c2dd-6639-44a7-9f03-e4fe478c266d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Step 2: Generating Flask Secret Key...\\n\")\n",
    "\n",
    "# Generate a secure random secret key for Flask\n",
    "FLASK_SECRET_KEY = secrets.token_hex(32)\n",
    "\n",
    "print(f\"âœ“ Flask secret key generated successfully!\")\n",
    "print(f\"  Key length: {len(FLASK_SECRET_KEY)} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffd49a46-9749-4921-8de8-fd1abc9ad638",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3: Create Secret Scope and Add Flask Secret Key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cea1624-5b81-4223-b77c-89cf567b7b84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Step 3: Creating Secret Scope...\\n\")\n",
    "\n",
    "try:\n",
    "    # Create secret scope\n",
    "    w.secrets.create_scope(scope=SECRET_SCOPE_NAME)\n",
    "    print(f\"Secret scope '{SECRET_SCOPE_NAME}' created successfully!\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        print(f\"Secret scope '{SECRET_SCOPE_NAME}' already exists. Using existing scope.\")\n",
    "    else:\n",
    "        print(f\"Error creating secret scope: {e}\")\n",
    "        raise\n",
    "\n",
    "# Add Flask secret key to the scope\n",
    "try:\n",
    "    w.secrets.put_secret(\n",
    "        scope=SECRET_SCOPE_NAME,\n",
    "        key=SECRET_KEY_NAME,\n",
    "        string_value=FLASK_SECRET_KEY\n",
    "    )\n",
    "    print(f\"Secret key '{SECRET_KEY_NAME}' added to scope successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error adding secret: {e}\")\n",
    "    raise\n",
    "\n",
    "# Verify the secret was created\n",
    "secrets_list = list(w.secrets.list_secrets(scope=SECRET_SCOPE_NAME))\n",
    "print(f\"\\nSecrets in scope '{SECRET_SCOPE_NAME}':\")\n",
    "for secret in secrets_list:\n",
    "    print(f\"  - {secret.key}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5552013-8d4c-4b4e-9d03-ef89582016fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4: Clone GitHub Repository to Workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc9b4f5b-33c3-496a-bb97-5979f98b0455",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Step 4: Cloning GitHub Repository...\\n\")\n",
    "\n",
    "try:\n",
    "    # Create the repo\n",
    "    repo = w.repos.create(\n",
    "        url=REPO_URL,\n",
    "        provider=REPO_PROVIDER\n",
    "    )\n",
    "    \n",
    "    print(f\"  Repository cloned successfully!\")\n",
    "    print(f\"  Repository ID: {repo.id}\")\n",
    "    print(f\"  Repository Path: {repo.path}\")\n",
    "    print(f\"  Branch: {repo.branch}\")\n",
    "    print(f\"  URL: {repo.url}\")\n",
    "    \n",
    "    REPO_WORKSPACE_PATH = repo.path\n",
    "    \n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        print(f\" Repository already exists at '{REPO_PATH}'. Using existing repository.\")\n",
    "        # Get the existing repo\n",
    "        try:\n",
    "            repo = w.repos.get(repo_id=REPO_PATH)\n",
    "            REPO_WORKSPACE_PATH = repo.path\n",
    "            print(f\"  Repository Path: {REPO_WORKSPACE_PATH}\")\n",
    "        except:\n",
    "            REPO_WORKSPACE_PATH = REPO_PATH\n",
    "            print(f\"  Using path: {REPO_WORKSPACE_PATH}\")\n",
    "    else:\n",
    "        print(f\" Error cloning repository: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d6c14e1-4b5d-4792-badb-5c19d313e20e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 5: Create app.yaml Configuration File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0293770c-7e0c-4987-ae4f-84c0a7298bd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Step 5: Creating app.yaml Configuration File...\\n\")\n",
    "\n",
    "# Create app.yaml content\n",
    "app_yaml_content = f\"\"\"command: [\"python\", \"app.py\"]\n",
    "env:\n",
    "  - name: 'DATABRICKS_HOST'\n",
    "    value: '{workspace_url}'\n",
    "  - name: 'PGDATABASE'\n",
    "    value: '{PGDATABASE}'\n",
    "  - name: 'POSTGRES_SCHEMA'\n",
    "    value: '{POSTGRES_SCHEMA}'\n",
    "  - name: 'PGPORT'\n",
    "    value: \"5432\"\n",
    "  - name: 'PGSSLMODE'\n",
    "    value: \"require\"\n",
    "  - name: 'PGAPPNAME'\n",
    "    value: \"inventory_app\"\n",
    "  # Schema and table configuration\n",
    "  - name: 'POSTGRES_TABLE'\n",
    "    value: \"{POSTGRES_TABLE}\"\n",
    "  - name: 'POSTGRES_CATEGORY_TABLE'\n",
    "    value: \"{POSTGRES_CATEGORY_TABLE}\"\n",
    "  - name: 'POSTGRES_WAREHOUSE_TABLE'\n",
    "    value: \"{POSTGRES_WAREHOUSE_TABLE}\"\n",
    "  - name: 'POSTGRES_SUPPLIER_TABLE'\n",
    "    value: \"{POSTGRES_SUPPLIER_TABLE}\"\n",
    "  - name: 'POSTGRES_SKU_TABLE'\n",
    "    value: \"{POSTGRES_SKU_TABLE}\"\n",
    "  - name: 'FORCE_DATA_RESET'\n",
    "    value: \"{FORCE_DATA_RESET}\"\n",
    "  - name: 'LOAD_SAMPLE_DATA'\n",
    "    value: \"{LOAD_SAMPLE_DATA}\"\n",
    "  - name: 'MODEL_ENDPOINT_NAME'\n",
    "    value: \"demand-forecasting-endpoint\"\n",
    "\"\"\"\n",
    "\n",
    "# Write app.yaml to the repository path\n",
    "app_yaml_path = f\"{REPO_WORKSPACE_PATH}/app.yaml\"\n",
    "\n",
    "try:\n",
    "    # Import workspace API\n",
    "    from databricks.sdk.service.workspace import ImportFormat\n",
    "    \n",
    "    # Write the file using workspace API\n",
    "    w.workspace.upload(\n",
    "        path=app_yaml_path,\n",
    "        content=app_yaml_content.encode('utf-8'),\n",
    "        format=ImportFormat.AUTO,\n",
    "        overwrite=True\n",
    "    )\n",
    "    \n",
    "    print(f\"  app.yaml created successfully!\")\n",
    "    print(f\"  Path: {app_yaml_path}\")\n",
    "    print(f\"\\nConfiguration:\")\n",
    "    print(f\"  Database: {PGDATABASE}\")\n",
    "    print(f\"  Schema: {POSTGRES_SCHEMA}\")\n",
    "    print(f\"  Table: {POSTGRES_TABLE}\")\n",
    "    print(f\"  Load Sample Data: {LOAD_SAMPLE_DATA}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Error creating app.yaml: {e}\")\n",
    "    print(f\"\\napp.yaml content (copy manually if needed):\\n\")\n",
    "    print(app_yaml_content)\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "288f199e-3d2c-4d59-9f5c-6dec50dd4ae5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 6: Create Databricks App\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "189b6432-4db5-4b21-b028-b4df03e4b257",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Step 6: Creating Databricks App with Resources...\\n\")\n",
    "\n",
    "try:\n",
    "    # Check if app already exists first\n",
    "    try:\n",
    "        app = w.apps.get(name=APP_NAME)\n",
    "        print(f\"  App '{APP_NAME}' already exists. Using existing app.\")\n",
    "        print(f\"  App Name: {app.name}\")\n",
    "        if hasattr(app, 'status'):\n",
    "            print(f\"  App Status: {app.app_status}\")\n",
    "    except Exception as get_error:\n",
    "        # App doesn't exist, create it using REST API\n",
    "        print(f\"App does not exist. Creating new app '{APP_NAME}' with resources...\")\n",
    "        \n",
    "        import requests\n",
    "        \n",
    "        # Prepare the REST API request\n",
    "        api_url = f\"{workspace_url}/api/2.0/apps\"\n",
    "        \n",
    "        # Get authentication token from workspace client\n",
    "        # The workspace client uses the notebook's authentication context\n",
    "        headers = w.config.authenticate()\n",
    "        \n",
    "        # Prepare the payload with app configuration and resources\n",
    "        payload = {\n",
    "            \"name\": APP_NAME,\n",
    "            \"description\": APP_DESCRIPTION,\n",
    "            \"resources\": [\n",
    "                {\n",
    "                    \"name\": \"database\",\n",
    "                    \"description\": \"Lakebase PostgreSQL database for inventory management\",\n",
    "                    \"database\": {\n",
    "                        \"database_name\": PGDATABASE,\n",
    "                        \"instance_name\": LAKEBASE_DB_NAME,\n",
    "                        \"permission\": \"CAN_CONNECT_AND_CREATE\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"secrets\",\n",
    "                    \"description\": \"Flask secret key for session management\",\n",
    "                    \"secret\": {\n",
    "                        \"scope\": SECRET_SCOPE_NAME,\n",
    "                        \"key\": SECRET_KEY_NAME,\n",
    "                        \"permission\": \"READ\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Make the REST API call to create the app\n",
    "        response = requests.post(\n",
    "            api_url,\n",
    "            headers=headers,\n",
    "            json=payload\n",
    "        )\n",
    "        \n",
    "        if response.status_code in [200, 201]:\n",
    "            app_response = response.json()\n",
    "            print(f\"  Databricks App '{APP_NAME}' created successfully with resources!\")\n",
    "            print(f\"  App Name: {app_response.get('name')}\")\n",
    "            print(f\"  Resources attached:\")\n",
    "            print(f\"    - Database: {LAKEBASE_DB_NAME} (Permission: CAN_CONNECT)\")\n",
    "            print(f\"    - Secret Scope: {SECRET_SCOPE_NAME}/{SECRET_KEY_NAME} (Permission: READ)\")\n",
    "        else:\n",
    "            print(f\"API call returned status {response.status_code}\")\n",
    "            print(f\"Response: {response.text}\")\n",
    "            raise Exception(\"App creation failed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Error with app creation: {e}\")\n",
    "    raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12f8181c-fa95-4ad4-a52d-7e0644adb281",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 7: Create Managed Database Catalog\n",
    "\n",
    "This creates a Unity Catalog catalog that connects to your Lakebase database instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e7b55dc-57da-4031-b18f-03aa49871820",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Step 7: Creating Managed Database Catalog...\\n\")\n",
    "\n",
    "try:\n",
    "    # Create the database catalog\n",
    "    catalog = DatabaseCatalog(\n",
    "        name=CATALOG_NAME,\n",
    "        database_instance_name=LAKEBASE_DB_NAME,\n",
    "        database_name=PGDATABASE,\n",
    "        create_database_if_not_exists=CREATE_CATALOG_IF_NOT_EXISTS\n",
    "    )\n",
    "    \n",
    "    print(f\"Creating catalog '{CATALOG_NAME}' for database instance '{LAKEBASE_DB_NAME}'...\")\n",
    "    \n",
    "    # Create the catalog\n",
    "    created_catalog = w.database.create_database_catalog(catalog=catalog)\n",
    "    \n",
    "    print(f\"  Database catalog '{CATALOG_NAME}' created successfully!\")\n",
    "    print(f\"  Catalog Name: {created_catalog.name}\")\n",
    "    print(f\"  Database Instance: {created_catalog.database_instance_name}\")\n",
    "    print(f\"  Logical Database: {created_catalog.database_name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    # Check if catalog already exists\n",
    "    if \"already exists\" in str(e).lower() or \"AlreadyExists\" in str(e):\n",
    "        print(f\" Catalog '{CATALOG_NAME}' already exists. Using existing catalog.\")\n",
    "        try:\n",
    "            existing_catalog = w.database.get_database_catalog(name=CATALOG_NAME)\n",
    "            print(f\"  Catalog Name: {existing_catalog.name}\")\n",
    "            print(f\"  Database Instance: {existing_catalog.database_instance_name}\")\n",
    "            print(f\"  Logical Database: {existing_catalog.database_name}\")\n",
    "        except Exception as get_error:\n",
    "            print(f\"  Note: Could not retrieve catalog details: {get_error}\")\n",
    "    else:\n",
    "        print(f\" Error creating database catalog: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9742493-8356-4328-a18f-bd956576375d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 8: Load and Parameterize Dashboard Template\n",
    "\n",
    "This loads the dashboard template and replaces the catalog name with your configured value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de21d284-69ac-408d-b4f7-7dca0bd1f149",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Step 8: Loading and Parameterizing Dashboard Template...\\n\")\n",
    "\n",
    "try:\n",
    "    # Read the dashboard template from the workspace\n",
    "    template_path = f\"/Workspace{REPO_WORKSPACE_PATH}/{DASHBOARD_TEMPLATE_PATH}\"\n",
    "    \n",
    "    print(f\"Reading dashboard template from: {template_path}\")\n",
    "    \n",
    "    # Download the file from workspace\n",
    "    file_info = w.workspace.download(path=template_path)\n",
    "    dashboard_template = json.loads(file_info.read())\n",
    "    \n",
    "    print(f\"âœ“ Dashboard template loaded successfully\")\n",
    "    \n",
    "    # Convert template to JSON string for regex replacement\n",
    "    dashboard_json_str = json.dumps(dashboard_template, indent=2)\n",
    "    \n",
    "    # Find the current catalog name in the template (pattern: catalog_name.schema_name.table_name)\n",
    "    # We'll look for patterns like \"reynoldspravindev_inventory_live.inventory_app.table_name\"\n",
    "    catalog_pattern = r'([a-zA-Z0-9_]+)\\.inventory_app\\.'\n",
    "    \n",
    "    # Find what catalog is currently in the template\n",
    "    match = re.search(catalog_pattern, dashboard_json_str)\n",
    "    if match:\n",
    "        old_catalog = match.group(1)\n",
    "        print(f\"  Found existing catalog in template: {old_catalog}\")\n",
    "        \n",
    "        # Replace all occurrences of the old catalog with the new one\n",
    "        dashboard_json_str = re.sub(\n",
    "            rf'{old_catalog}\\.{POSTGRES_SCHEMA}\\.', \n",
    "            f'{CATALOG_NAME}.{POSTGRES_SCHEMA}.', \n",
    "            dashboard_json_str\n",
    "        )\n",
    "        \n",
    "        print(f\"  Replaced '{old_catalog}' with '{CATALOG_NAME}'\")\n",
    "    else:\n",
    "        print(f\"  âš  Could not find catalog pattern in template. Using template as-is.\")\n",
    "    \n",
    "    # Convert back to JSON object\n",
    "    dashboard_definition = json.loads(dashboard_json_str)\n",
    "    \n",
    "    print(f\"âœ“ Dashboard template parameterized successfully\")\n",
    "    print(f\"  Catalog: {CATALOG_NAME}\")\n",
    "    print(f\"  Schema: {POSTGRES_SCHEMA}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error loading/parameterizing dashboard template: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3571fe9-7d0b-4ac1-8be8-d2df5fe5ce6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 9: Create or Update Databricks Lakeview Dashboard\n",
    "This creates a new dashboard or updates an existing one if a dashboard ID is provided in app.yaml.\n",
    "\n",
    "**Note:** This step might run longer if the workspace has a large number of AI/BI Dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e22c65b-5535-4075-9738-fd3768ce80f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Step 9: Creating/Updating Databricks Lakeview Dashboard...\\n\")\n",
    "\n",
    "try:\n",
    "    # Check if dashboard ID exists in app.yaml\n",
    "    app_yaml_path = f\"/Workspace{REPO_WORKSPACE_PATH}/app.yaml\"\n",
    "    existing_dashboard_id = None\n",
    "    \n",
    "    try:\n",
    "        app_yaml_content = w.workspace.download(path=app_yaml_path).contents.read().decode('utf-8')\n",
    "        \n",
    "        # Extract DASHBOARD_ID from app.yaml\n",
    "        dashboard_id_match = re.search(r\"DASHBOARD_ID['\\\"]?\\s*\\n\\s*value:\\s*['\\\"]([^'\\\"]+)['\\\"]?\", app_yaml_content)\n",
    "        existing_dashboard_id = dashboard_id_match.group(1) if dashboard_id_match and dashboard_id_match.group(1) else None\n",
    "        \n",
    "        if existing_dashboard_id and existing_dashboard_id.strip():\n",
    "            print(f\"Found existing dashboard ID in app.yaml: {existing_dashboard_id}\")\n",
    "        else:\n",
    "            existing_dashboard_id = None\n",
    "            print(\"No dashboard ID found in app.yaml.\")\n",
    "    except:\n",
    "        print(\"Could not read app.yaml.\")\n",
    "    \n",
    "    # If no dashboard ID in app.yaml, check if a dashboard with this name already exists in workspace\n",
    "    if not existing_dashboard_id:\n",
    "        print(f\"Checking workspace for existing dashboard with name '{DASHBOARD_DISPLAY_NAME}'...\")\n",
    "        try:\n",
    "            # List all dashboards and find one with matching display name\n",
    "            all_dashboards = list(w.lakeview.list())\n",
    "            for dashboard in all_dashboards:\n",
    "                if dashboard.display_name == DASHBOARD_DISPLAY_NAME:\n",
    "                    existing_dashboard_id = dashboard.dashboard_id\n",
    "                    print(f\" Found existing dashboard in workspace: {existing_dashboard_id}\")\n",
    "                    break\n",
    "            \n",
    "            if not existing_dashboard_id:\n",
    "                print(\"No existing dashboard found in workspace. Will create new dashboard.\")\n",
    "        except Exception as list_error:\n",
    "            print(f\"Could not list dashboards: {list_error}\")\n",
    "            print(\"Will attempt to create new dashboard.\")\n",
    "    \n",
    "    # Determine warehouse ID\n",
    "    if WAREHOUSE_ID is None:\n",
    "        # Get the first available SQL warehouse\n",
    "        warehouses = list(w.warehouses.list())\n",
    "        if warehouses:\n",
    "            warehouse_id = warehouses[0].id\n",
    "            print(f\"Using warehouse: {warehouses[0].name} (ID: {warehouse_id})\")\n",
    "        else:\n",
    "            raise Exception(\"No SQL warehouses found. Please create one or specify WAREHOUSE_ID.\")\n",
    "    else:\n",
    "        warehouse_id = WAREHOUSE_ID\n",
    "        print(f\"Using specified warehouse ID: {warehouse_id}\")\n",
    "    \n",
    "    # Create or update dashboard using Lakeview API\n",
    "    if existing_dashboard_id:\n",
    "        # Update existing dashboard\n",
    "        print(f\"\\nUpdating existing dashboard '{existing_dashboard_id}'...\")\n",
    "        \n",
    "        try:\n",
    "            # Get the current dashboard\n",
    "            current_dashboard = w.lakeview.get(dashboard_id=existing_dashboard_id)\n",
    "            \n",
    "            # Update the dashboard with correct API signature\n",
    "            updated_dashboard = w.lakeview.update(\n",
    "                dashboard_id=existing_dashboard_id,\n",
    "                dashboard=Dashboard(\n",
    "                    display_name=DASHBOARD_DISPLAY_NAME,\n",
    "                    serialized_dashboard=json.dumps(dashboard_definition),\n",
    "                    warehouse_id=warehouse_id\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Publish the dashboard\n",
    "            published = w.lakeview.publish(dashboard_id=existing_dashboard_id)\n",
    "            \n",
    "            dashboard_id = existing_dashboard_id\n",
    "            print(f\"Dashboard updated and published successfully!\")\n",
    "            \n",
    "        except Exception as update_error:\n",
    "            print(f\"Could not update existing dashboard: {update_error}\")\n",
    "            print(f\"Will continue to use existing dashboard without updating...\")\n",
    "            dashboard_id = existing_dashboard_id\n",
    "    \n",
    "    if not existing_dashboard_id:\n",
    "        # Create new dashboard\n",
    "        print(f\"\\nCreating new dashboard '{DASHBOARD_DISPLAY_NAME}'...\")\n",
    "        \n",
    "        # Create the dashboard\n",
    "        new_dashboard = w.lakeview.create(\n",
    "            Dashboard(\n",
    "                display_name=DASHBOARD_DISPLAY_NAME,\n",
    "                serialized_dashboard=json.dumps(dashboard_definition),\n",
    "                warehouse_id=warehouse_id,\n",
    "                parent_path=f\"/Users/{current_user.user_name}\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        dashboard_id = new_dashboard.dashboard_id\n",
    "        \n",
    "        # Publish the dashboard\n",
    "        published = w.lakeview.publish(dashboard_id=dashboard_id)\n",
    "        \n",
    "        print(f\"Dashboard created and published successfully!\")\n",
    "    \n",
    "    print(f\"  Dashboard ID: {dashboard_id}\")\n",
    "    print(f\"  Dashboard URL: {workspace_url}/sql/dashboardsv3/{dashboard_id}\")\n",
    "    \n",
    "    # Store dashboard ID for next step\n",
    "    CREATED_DASHBOARD_ID = dashboard_id\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating/updating dashboard: {e}\")\n",
    "    print(f\"\\nNote: Make sure you have permissions to create dashboards and that the warehouse is running.\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06fbd369-4988-48f6-ac4a-e7c4b891c623",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 10: Update app.yaml with Dashboard ID\n",
    "\n",
    "This updates the app.yaml file with the dashboard ID so the app can embed the dashboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5979534f-a50d-44bf-b08f-40b39344d5f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Step 10: Updating app.yaml with Dashboard ID...\\n\")\n",
    "\n",
    "try:\n",
    "    # Read current app.yaml\n",
    "    app_yaml_path = f\"/Workspace{REPO_WORKSPACE_PATH}/app.yaml\"\n",
    "    app_yaml_content = w.workspace.download(path=app_yaml_path).read().decode('utf-8')\n",
    "    \n",
    "    print(f\"Reading app.yaml from: {app_yaml_path}\")\n",
    "    \n",
    "    # Update DASHBOARD_ID value\n",
    "    # Pattern matches: - name: 'DASHBOARD_ID'\\n    value: 'old_value'\n",
    "    dashboard_pattern = r\"(- name: ['\\\"]DASHBOARD_ID['\\\"]?\\s*\\n\\s*value: ['\\\"]?)([^'\\\"]*)([\\'\\\"]?)\"\n",
    "    \n",
    "    if re.search(dashboard_pattern, app_yaml_content):\n",
    "        # Replace existing dashboard ID\n",
    "        updated_yaml = re.sub(\n",
    "            dashboard_pattern,\n",
    "            rf\"\\g<1>{CREATED_DASHBOARD_ID}\\g<3>\",\n",
    "            app_yaml_content\n",
    "        )\n",
    "        print(f\"  Updated existing DASHBOARD_ID value\")\n",
    "    else:\n",
    "        # Add DASHBOARD_ID if it doesn't exist\n",
    "        updated_yaml = app_yaml_content.rstrip() + f\"\\n  - name: 'DASHBOARD_ID'\\n    value: '{CREATED_DASHBOARD_ID}'\\n\"\n",
    "        print(f\"  Added DASHBOARD_ID to app.yaml\")\n",
    "    \n",
    "    # Write updated app.yaml back to workspace\n",
    "    w.workspace.upload(\n",
    "        path=app_yaml_path,\n",
    "        content=updated_yaml.encode('utf-8'),\n",
    "        format=ImportFormat.AUTO,\n",
    "        overwrite=True\n",
    "    )\n",
    "    \n",
    "    print(f\"  app.yaml updated successfully!\")\n",
    "    print(f\"  Dashboard ID: {CREATED_DASHBOARD_ID}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Error updating app.yaml: {e}\")\n",
    "    print(f\"\\nPlease manually update app.yaml with:\")\n",
    "    print(f\"  - name: 'DASHBOARD_ID'\")\n",
    "    print(f\"    value: '{CREATED_DASHBOARD_ID}'\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6698a41a-4a6f-468c-8ad4-49a0287f33d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 11: Deploy Databricks App\n",
    "\n",
    "This deploys the Databricks App with the updated app.yaml configuration for dashboard embedding.\n",
    "\n",
    "**Note**: The app domain needs to be [configured](https://docs.databricks.com/aws/en/ai-bi/admin/embed#-control-allowed-embed-destinations) for the embedding to work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01c6b2c2-af87-4e93-9dab-b6c899161ce5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sleep(360) # Give time for App to be created\n",
    "\n",
    "print(\"Step 11: Deploying Databricks App...\\n\")\n",
    "try:\n",
    "    print(f\"Deploying app '{APP_NAME}' with updated configuration...\")\n",
    "    \n",
    "    # Create deployment configuration\n",
    "    app_deployment = AppDeployment(\n",
    "        source_code_path=\"/Workspace\"+REPO_WORKSPACE_PATH\n",
    "    )\n",
    "    \n",
    "    # Deploy the app\n",
    "    deployment = w.apps.deploy_and_wait(\n",
    "        app_name=APP_NAME,\n",
    "        app_deployment=app_deployment,\n",
    "        timeout=timedelta(minutes=20)\n",
    "    )\n",
    "    \n",
    "    print(f\"  App deployment completed!\")\n",
    "    print(f\"  Deployment ID: {deployment.deployment_id}\")\n",
    "    print(f\"  Status: {deployment.status}\")\n",
    "    \n",
    "    # Get app status and URL\n",
    "    app_status = w.apps.get(name=APP_NAME)\n",
    "    if hasattr(app_status, 'url') and app_status.url:\n",
    "        print(f\"  App URL: {app_status.url}\")\n",
    "        print(f\"\\n  Your app is now deployed with the embedded dashboard!\")\n",
    "        print(f\"\\nAccess your app at: {app_status.url}\")\n",
    "        print(f\"View the dashboard at: {workspace_url}/sql/dashboardsv3/{CREATED_DASHBOARD_ID}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Error Deploying app: {e}\")\n",
    "    print(f\"\\nYou can manually redeploy using the command in the cell below.\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b09bb42f-06a7-4a73-b142-0d27a3461021",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### NEXT STEPS\n",
    "#### Follow below steps to enable Genie on the AI/BI Dashboard that got created in order to use Genie from the Databricks Inventory App.\n",
    "- Navigate to the created dashboard named \"Lakebase Inventory Dashboard\"\n",
    "- Click Edit Draft.\n",
    "- In the right panel, click Settings. Or, click Kebab menu icon. the kebab menu > Settings to open settings.\n",
    "- Click General.\n",
    "- The Enable Genie toggle is off by default. Turn the toggle on to allow dashboard viewers to use the associated Genie space.\n",
    "- (Optional) To link an existing Genie space, select the Link existing Genie space radio button and paste in the associated URL. If you don't select this option, Databricks automatically generates a new Genie space based on your dashboard when you publish.\n",
    "- Click publish and select \"unpublish\"\n",
    "- Now re-publish the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43117803-4fbf-4f42-8959-35c339f8d4d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ðŸŽ‰ Deployment Complete!\n",
    "\n",
    "Your BI dashboard has been successfully deployed! Here's what was created:\n",
    "\n",
    "1. **Database Catalog**: Unity Catalog catalog connected to your Lakebase instance\n",
    "2. **Lakeview Dashboard**: Interactive dashboard with your inventory analytics\n",
    "3. **App Configuration**: Updated app.yaml with dashboard ID\n",
    "4. **App Redeployment**: Your app is now running with the embedded dashboard\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Access your app and navigate to the Dashboard page to see the embedded analytics\n",
    "- Customize the dashboard by editing it in the Databricks SQL UI\n",
    "- Share the dashboard with your team using Databricks permissions\n",
    "- Proceed to **1.1GenerateSyntheticSalesData** notebook\n",
    "\n",
    "### Troubleshooting:\n",
    "\n",
    "If the dashboard doesn't appear in your app:\n",
    "1. Verify the dashboard ID in app.yaml matches the created dashboard\n",
    "2. Ensure your app has permissions to access the SQL warehouse\n",
    "3. Check that the catalog and schema names match your Lakebase configuration\n",
    "4. Manually redeploy using the command below if needed\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "1 - Deploy Assets",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
